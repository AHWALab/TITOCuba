# Threading Inputs to Outputs (TITO): 

TITO is a framework designed to run the EF5 hydrologic model operationally, integrating satellite data, machine learning techniques and NWP products to support real-time forecasting and hydrologic analysis.

## Installation Instructions
**1. Clone the repository**
  ```sh
  git clone https://github.com/AHWALab/TITO.git
  ```
**2. Navigate to the repository folder**
  ```sh
  cd TITO/
  ```
**3. Run the set up code**
   This step might take few minutes. 
  ```sh
  bash setup_tito.sh
  ```
**4. Getting the files ready**

- The 25m DEMs are large in size so they are provided in the following [Zenodo link](https://zenodo.org/records/17716930). After downloading, all the TIF files should be extracted to the `basic/` folder.
- Similarly, parameters and precomputed Data Assimilation CSV files are also provided on Zenodo. The parameters zip should be extracted in the `parameters/` folder and Data Assimilation data should be extracted in the `DA_Climatology/` folder.

After installation, ensure that your TITO folder contains the following subdirectories and files.

## Repository structure

This repository is designed to run EF5 operationally over Cuba. 

### Key Files & Folders
- **`Cuba_config.py`** – Configuration file to set up your operational run.
- **`orchestrator.py`** – Main Python script that manages the entire workflow.
- **`pipeline.sh`** – Bash script that activates the `tito_env` Conda environment and executes `orchestrator.py` using settings from `Cuba_config.py`.

### Input / Output Directories
- **`basic/`** – Contains DEM, FAC, and FDIR files.
- **`pet/`** – Contains monthly PET (Potential Evapotranspiration) grids.
- **`parameters/`** – Contains distributed parameters for the KW and CREST models.
- **`states/`** – Stores model state files generated during operational runs.
- **`statesHighRes/`** – Stores states generated from the 1 km run for use in the 25 m model.
- **`outputs/`** – Output folder where simulation results are saved.
- **`outputs_25m/`** – Output folder where 25 m simulation results are saved.
- **`precip/`** – IMERG QPE files are downloaded here; nowcast files generated by the nowcasting system are also stored here.
- **`precipEF5/`** – QPE and QPE_nowcast-based files are reformatted and copied here to be ingested by EF5.
- **`DA_Climatology/`** – Contains precomputed averaged reservoir data for data assimilation from December 2025 to January 2031. This data is used when no observed data is manually provided for the reservoirs.
- **`DA_Manual/`** – Stores manually entered observed reservoir data for data assimilation. If data is present for the current simulation period, it will be used instead of the climatology data.
- **`DA_Consolidated/`** – TITO automatically creates a consolidated list of observed data for all reservoirs by selecting either precomputed climatology or manual data. This file is refreshed with every simulation run.
- **`DA_Simulation/`** – TITO automatically generates individual CSV files for each reservoir containing observed data for the current simulation period. These files are refreshed with every simulation run.
- **`templates/`** – Stores EF5 control file templates, which are dynamically updated during each run.
- **`qpf_store/`** – Stores QPF files for using during QPF-based runs.
- **`Nowcast/`** – Contains machine learning routines used to generate QPF forecasts.
- **`tito_utils/`** – Collection of utility modules and helper scripts used internally by TITO.

## How to run?
**1. Edit the config file:**
After completing the installation of the required environment and populating the corresponding EF5 folders, open `Cuba_config.py` file. There are few lines users need to change in this config file to run TITO successfully:
- **ef5Path:** Update this path to the corresponding ef5's binary path in your system.
- **HindCastMode:** If you are running an event happened in the PAST, set `HindCastMode = True` and write the date of interest in `HindCastDate`, use the format "YYYY-MM-DD HH:MM". If you want to run it in Nowcast Mode (meaning TITO will start running in the present time) set `HindCastMode = False`
- **run_LR:** To include QPF in the simulation (options are GFS or WRF), set `run_LR = True`.  
  - If the simulation is for a **past event** (`HindCastMode = True`), you must provide:  
    - QPF start date (`StartLRtime`)  
    - QPF end date (`EndLRtime`)  
    - QPF time step (`LR_timestep`) in minutes, e.g., `30u`  
    - Path to your QPF archive (`QPF_archive_path`)  
  - If you are activating this option for **real-time operations**, TITO uses a predefined QPF time. You can check `orchestrator.py` to customize it for your convenience.
- **email_gpm:** This version of TITO uses IMERG Early V07 as QPE. You will need to create an account on the GPM server to download precipitation files. Please visit the [NASA GPM registration web page](https://registration.pps.eosdis.nasa.gov/registration/) and follow the instructions provided on the webpage. **Important:** Use your registration email as the password so TITO can use it in the routines.

**What if I want to use TITO in other regions?**

If you plan to run TITO outside the default West Africa domain, there are a few important considerations. The machine learning routines were designed and trained using IMERG V07 data (0.1° resolution) over the West Africa region (xmin = −21.4, xmax = 30.4; ymin = −2.9, ymax = 33.1), corresponding to a grid size of **518 × 360 pixels**.

If you intend to apply TITO to a different region, we recommend selecting an area with the same spatial dimensions (518 × 360 pixels) to ensure compatibility with the input structure.

**Before running TITO, verify your configuration paths:**

Open `Cuba_config.py` and ensure the following settings are correct:

- **Basic input directories:** Verify that the essential input folders are properly populated:
  - `basic/` – Should contain DEMs for both 1 km and 25 m resolutions
  - `pet/` – Should contain monthly PET (Potential Evapotranspiration) grids
  - `parameters/` – Should contain distributed parameters for the KW and CREST models for the 1 km model, and `parameters/highResPara/` should contain parameters for the KW and CREST models for the 25 m model

- **High-resolution EF5 rerun settings:** Check that all paths for the 25 m resolution run are properly configured:
  - `highres_template` – Path to the high-resolution control file template
  - `highres_maskgrid` – Path to the mask grid file
  - `highres_gauge_list` – Path to the gauge list file
  - `highres_dataPath` – Output folder for 25 m results
  - `statesHighResPath` – Folder for high-resolution model states

- **Data Assimilation (DA) configuration:** Verify all DA folder paths exist and are correct:
  - `DA_climatology_path` – Folder containing precomputed averaged reservoir data
  - `DA_manual_path` – Folder for manually entered observed data
  - `DA_consolidated_path` – Folder where consolidated data will be created
  - `DA_simulation_path` – Folder where individual reservoir CSV files will be generated
  - `DA_list_path` – Path to the list of reservoirs for data assimilation

**2. Run TITO:**
  Run the following line in your terminal:
  ```sh
  ./pipeline.sh
  ```

  Logs from the pipeline can be viewed in `data/logs/`.

**Note on running the GFS downloader script:**

It is advised to run the GFS download script in the background separately because GFS releases often go through delays. With every simulation, the script sometimes cannot find the latest GFS release, so it re-downloads the previous cycle, which is time-consuming. The GFS script under `tito_utils/qpf_utils/gfs_downloader.py` also supports background execution and will automatically check for new releases and keep the GFS files updated.

To run this script in the background:

1. Inside the terminal at the TITO root directory, activate the tito conda environment:
   ```sh
   conda activate tito_env
   ```

2. Run this script using the below command to keep the latest GFS files updated:
   ```sh
   nohup python tito_utils/qpf_utils/gfs_downloader.py --auto-out /home/<user>/<tito root>/precip/GFS > /home/<user>/<tito root>/data/logs/gfs_downloader.log 2>&1 &
   ```

   Logs from the script can be viewed in `data/logs/gfs_downloader.log`.

Details of how TITO operates can be found in this document (placeholder).

## Contact
Please contact Vanessa Robledo at vanessa-robledodelgado@uiowa.edu or the [AHWA Laboratory](https://ahwa.lab.uiowa.edu/) Development team at engr-ahwa-lab@uiowa.edu.

## Cite this package
Robledo Delgado, V., & Vergara, H. (2025). Threading Inputs to Outputs (TITO) (v2.0.0). Zenodo. https://doi.org/10.5281/zenodo.17246491
