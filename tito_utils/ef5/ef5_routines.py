import os
import shutil
import re
import glob
from shutil import rmtree
import datetime
from datetime import timedelta
from multiprocessing.pool import ThreadPool
import subprocess
from tito_utils.file_utils.file_handling import is_non_zero_file, mkdir_p
from tito_utils.ef5.alerts import send_mail

def rename_ef5_precip(precipEF5Folder, precipFolder): 
    """
    Move the qpe and qpf files into precipEF5folder to be ingested by EF5 using
    a unify format.
    """   
    # Collect .tif files, sort by the embedded timestamp (YYYYMMDDHHMM) so that
    # the last 4 correspond to the newest 4 timesteps, then skip those.
    tif_files = [f for f in os.listdir(precipFolder) if f.endswith('.tif')]

    def _extract_timestamp(name: str) -> str:
        # Matches the 12-digit timestamp segment like 202306062030 in
        # imerg.qpf.202306062030.30minAccum.tif
        m = re.search(r'\.(\d{12})\.', name)
        return m.group(1) if m else ''  # Empty string sorts before valid timestamps

    # Sort oldest -> newest by timestamp string (lexicographic works with zero padding)
    tif_files.sort(key=_extract_timestamp)

    files_to_copy = tif_files[:-4] if len(tif_files) > 4 else tif_files

    for filename in files_to_copy:
        source_file = os.path.join(precipFolder, filename)
        dest_file = os.path.join(precipEF5Folder, filename)
        try:
            shutil.copy(source_file, dest_file)
        except PermissionError as e:
            print(f"PermissionError: {e}")
    for filename2 in os.listdir(precipEF5Folder):
        if 'qpf' in filename2 and filename2.endswith('.tif'):
            new_filename = filename2.replace('qpf', 'qpe')
            source_file = os.path.join(precipEF5Folder, filename2)
            dest_file = os.path.join(precipEF5Folder, new_filename)
            try:
                os.rename(source_file, dest_file)
            except PermissionError as e:
                print(f"PermissionError: {e}")


def find_available_states(statesPath, modelStates, systemStartTime, failTime):
    """
    Look for the set of most recent states available.
    
    """
    foundAllStates = False
    realSystemStartTime = systemStartTime

    print("    Looking for states.")

    # Iterate over all necessary states and check if they're available for the current run
    # Only go back up to 6 hours, in 30min decrements
    while not foundAllStates and realSystemStartTime > failTime:
        foundAllStates = True
        for state in modelStates:
            state_path = f"{statesPath}{state}_{realSystemStartTime.strftime('%Y%m%d_%H%M')}.tif"
            if not is_non_zero_file(state_path):
                print(f"    Missing start state: {state_path}")
                foundAllStates = False
        if not foundAllStates:
            realSystemStartTime -= timedelta(minutes=30)
        else:
            # All states found for this time - log the successful find
            print(f"    Found all states for time: {realSystemStartTime.strftime('%Y%m%d_%H%M')}")
            for state in modelStates:
                state_path = f"{statesPath}{state}_{realSystemStartTime.strftime('%Y%m%d_%H%M')}.tif"
                print(f"    Using start state: {state_path}")

    return foundAllStates, realSystemStartTime


def send_state_alerts(foundAllStates,realSystemStartTime,systemStartTime,currentTime,systemName,SEND_ALERTS,alert_recipients, smtp_config):
    """
    Sends alert emails if necessary based on the availability of model states.

    Args:
        foundAllStates (bool): whether all required states were found
        realSystemStartTime (datetime): actual start time used for the simulation
        systemStartTime (datetime): originally planned system start time
        currentTime (datetime): current system time
        systemName (str): name of the system sending the alert
        SEND_ALERTS (bool): whether to send email alerts or not
        alert_recipients (list): list of email addresses to notify
        smtp_config (dict): configuration dictionary containing:
            - smtp_server (str)
            - smtp_port (int)
            - account_address (str)
            - account_password (str)
            - alert_sender (str)
    """
    # Exit early if email alerts are disabled
    if not SEND_ALERTS:
        return

    # If no valid states were found, notify about a cold start
    if not foundAllStates:
        subject = f"{systemName} failed for {currentTime.strftime('%Y%m%d_%H%M')}"
        message = (
            f"Missing states from {realSystemStartTime.strftime('%Y%m%d_%H%M')} "
            f"to {systemStartTime.strftime('%Y%m%d_%H%M')}. Starting model with cold states."
        )
    
    # If older states had to be used, notify about it
    elif realSystemStartTime != systemStartTime:
        subject = f"{systemName} warning for {currentTime.strftime('%Y%m%d_%H%M')}"
        message = (
            f"Using states from {realSystemStartTime.strftime('%Y%m%d_%H%M')} "
            f"instead of {systemStartTime.strftime('%Y%m%d_%H%M')}."
        )
    
    # If states were found and up to date, no alert needed
    else:
        return

    # Send the email to each recipient in the list
    for recipient in alert_recipients:
        send_mail(
            smtp_server=smtp_config['smtp_server'],
            smtp_port=smtp_config['smtp_port'],
            account_address=smtp_config['account_address'],
            account_password=smtp_config['account_password'],
            sender=smtp_config['alert_sender'],
            to=recipient,
            subject=subject,
            text=message
        )

def write_control_file(tmpOutput, dataPath, subdomain, systemModel,templatePath, template, statesPath, realSystemStartTime, systemStartLRTime, systemWarmEndTime, systemStateEndTime, systemEndTime, LR_TimeStep, LR_run, statesFound):
    # Clean up "Hot" folders
    # Delete the previously existing "Hot" folders, ignore error if it doesn't exist
    # COMMENTED OUT FOR DEBUGGING - to examine generated control file
    rmtree(tmpOutput, ignore_errors=1)
    rmtree(dataPath, ignore_errors=1)
    # Create the "Hot" folder for the current run
    mkdir_p(tmpOutput)
    mkdir_p(dataPath)  
    # Create the control files for both subdomains
    # Define the control file path to create
    controlFile = tmpOutput + "WA_" + subdomain + "_" + systemModel + ".txt"
    fOut = open(controlFile, "w")

    # Create a control file with updated fields
    for line in open(templatePath + template).readlines():
        line = re.sub('{OUTPUTPATH}', tmpOutput, line)
        line = re.sub('{STATESPATH}', statesPath, line)
        line = re.sub('{TIMEBEGIN}', realSystemStartTime.strftime('%Y%m%d%H%M'), line)
        line = re.sub('{TIMEWARMEND}', systemWarmEndTime.strftime('%Y%m%d%H%M'), line)
        line = re.sub('{TIMESTATE}', systemStateEndTime.strftime('%Y%m%d%H%M'), line)
        line = re.sub('{TIMEEND}', systemEndTime.strftime('%Y%m%d%H%M'), line)
        line = re.sub('{TIMEBEGINLR}', systemStartLRTime.strftime('%Y%m%d%H%M'), line)
        line = re.sub('{TIMESTEPLR}', LR_TimeStep, line)
        line = re.sub('{SYSTEMMODEL}', systemModel, line)
        
        if "task=Simulation_QPE" in line:
            if LR_run:                      # QPF mode
                line = "#task=Simulation_QPE\n"   # comment QPE
        elif "task=Simulation_QPF" in line:
            if LR_run:
                line = "task=Simulation_QPF\n"    # uncomment QPF
            else:
                line = "#task=Simulation_QPF\n"   # comment QPF
        
        # If valid states are found, do not specify warm-up in control file
        if statesFound and "TIME_WARMEND=" in line:
            if not line.lstrip().startswith('#'):
                line = "#" + line
        fOut.write(line)
        
    fOut.close()
    return controlFile

def run_EF5(ef5Path, hot_folder_path, control_file, log_file):
    """
    Run EF5 as a subprocess call
    Arguments:
        ef5Path {str} -- Path to EF5 binary
        hot_folder_path {str} -- Path to the current run's "hot" foler
        control_file {str} -- path to the control file fir the simulation
        log_file {str} -- path to the log file for this run
    """
    subprocess.call(ef5Path + " " + control_file + " > " + hot_folder_path + log_file, shell=True)


def _rename_outputs_with_timestamp(hot_folder_path: str, timestamp_str: str) -> None:
    """Rename EF5 outputs in the hot folder to use a unified timestamp.

    - maxq.*, maxunitq.*, qpeaccum.*, qpfaccum.* -> base.{timestamp}.tif
    - ts.*.csv -> ts.*.{timestamp}.csv
    Log file naming is handled via the EF5 invocation (redirect target).
    """
    bases = ["maxq", "maxunitq", "qpeaccum", "qpfaccum", "maxsm"]
    for base in bases:
        pattern = os.path.join(hot_folder_path, f"{base}.*.tif")
        matches = sorted(glob.glob(pattern))
        if not matches:
            continue
        # Prefer the newest file in case multiple exist
        latest = max(matches, key=lambda p: os.path.getmtime(p))
        new_name = os.path.join(hot_folder_path, f"{base}.{timestamp_str}.tif")
        try:
            if os.path.abspath(latest) != os.path.abspath(new_name):
                if os.path.exists(new_name):
                    os.remove(new_name)
                os.rename(latest, new_name)
        except Exception as e:
            print(f"Warning: could not rename {latest} -> {new_name}: {e}")

    # Timeseries CSVs
    for csv_path in glob.glob(os.path.join(hot_folder_path, "ts.*.csv")):
        root, ext = os.path.splitext(csv_path)
        new_name = f"{root}.{timestamp_str}{ext}"
        try:
            if os.path.abspath(csv_path) != os.path.abspath(new_name):
                if os.path.exists(new_name):
                    os.remove(new_name)
                os.rename(csv_path, new_name)
        except Exception as e:
            print(f"Warning: could not rename {csv_path} -> {new_name}: {e}")


def run_ef5_simulation(ef5Path, tmpOutput, controlFile, output_timestamp_str):
    # Use timestamped log name
    log_name = f"ef5.{output_timestamp_str}.log"
    args = [ef5Path, tmpOutput, controlFile, log_name]
    tp = ThreadPool(1)
    tp.apply_async(run_EF5, args)
    tp.close()
    tp.join()

    # Rename generated outputs to use the requested timestamp
    _rename_outputs_with_timestamp(tmpOutput, output_timestamp_str)

    # cleaning EF5 precipitation for next cycle
    for f in glob.glob("precipEF5/*"):
        os.remove(f)

 
def prepare_ef5(precipEF5Folder, precipFolder, statesPath, modelStates, 
    systemStartTime, failTime, currentTime, systemName, SEND_ALERTS, 
    alert_recipients, smtp_config, tmpOutput, dataPath, 
    subdomain, systemModel, templatePath, template, systemStartLRTime, 
    systemWarmEndTime, systemStateEndTime, systemEndTime, LR_TimeStep, LR_run):

    #copying precip files into folder 
    rename_ef5_precip(precipEF5Folder, precipFolder) 

    # Check to see if all the states for the current time step are available: ["crest_SM", "kwr_IR", "kwr_pCQ", "kwr_pOQ"]
    # If not then search for previous ones

    foundAllStates, realSystemStartTime = find_available_states(statesPath, modelStates, systemStartTime, failTime)

    # send alerts if needed 
    send_state_alerts(foundAllStates, realSystemStartTime, systemStartTime,
                      currentTime, systemName, SEND_ALERTS,
                      alert_recipients, smtp_config)
                     
    print(" ")
    print("    Writting control file.")

    controlFile = write_control_file(tmpOutput, dataPath, subdomain, systemModel, 
    templatePath, template, statesPath, realSystemStartTime, systemStartLRTime, 
    systemWarmEndTime, systemStateEndTime, systemEndTime, LR_TimeStep, LR_run, foundAllStates)

    """
    # If data assimilation if being used for CREST, clean up previous data assimilation logs
    #To do: Verify against EF5 control file - when this functionality is needed
    if DATA_ASSIMILATION and systemModel=="crest":
        # Data assimilation output files
        for log in assimilationLogs:
            if is_non_zero_file(assimilationPath + log) == True:
                remove(assimilationPath + log)
    """
    return realSystemStartTime, controlFile
